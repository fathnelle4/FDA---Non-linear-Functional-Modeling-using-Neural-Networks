{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d180548",
   "metadata": {},
   "source": [
    "# Simulation of Empirical Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a3908a",
   "metadata": {},
   "source": [
    "### Simulation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d909fa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 08:34:44.353409: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-04 08:34:44.389012: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-04 08:34:45.301966: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import cholesky\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# from rpy2.robjects.packages import importr\n",
    "# from rpy2.robjects import pandas2ri\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.interpolate import BSpline, splrep, splev\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_openml\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52466be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set R = 1 to focus only on the complexity of the relationship between \n",
    "# a function and the response variable.\n",
    "\n",
    "# time grid \n",
    "m = 200\n",
    "t = np.linspace(0, 1, m)\n",
    "dt = t[1] - t[0]\n",
    "\n",
    "# Covariance Matérn (ν = 5/2)\n",
    "def matern52_cov(t, rho=0.5, sigma=1.0):\n",
    "    T1, T2 = np.meshgrid(t, t)\n",
    "    r = np.abs(T1 - T2)\n",
    "    sqrt5_r = np.sqrt(5) * r / rho\n",
    "    return sigma**2 * (1 + sqrt5_r + 5*r**2/(3*rho**2)) * np.exp(-sqrt5_r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89aa99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of function Xi(t)\n",
    "\n",
    "def simulate_functions(n, t):\n",
    "    cov = matern52_cov(t)\n",
    "    L = cholesky(cov + 1e-6*np.eye(len(t)))\n",
    "    Z = np.random.randn(n, len(t))\n",
    "    return Z @ L.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce93343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenerios of true relation between Y ansd Xi(t)\n",
    "\n",
    "def scenario_linear(X):\n",
    "    beta = 5 * np.sin(2*np.pi*t)\n",
    "    return (X @ beta) * dt + np.random.randn(len(X))\n",
    "\n",
    "def scenario_cam(X):\n",
    "    return np.sum(X**2, axis=1) * dt + np.random.randn(len(X))\n",
    "\n",
    "def scenario_single_index(X):\n",
    "    beta = 5 * np.sin(2*np.pi*t)\n",
    "    z = (X @ beta) * dt\n",
    "    return z**2 + np.random.randn(len(X))\n",
    "\n",
    "def scenario_multiple_index(X):\n",
    "    beta1 = 5 * np.sin(2*np.pi*t)\n",
    "    beta2 = 5 * np.sin(3*np.pi*t)\n",
    "    z1 = (X @ beta1) * dt\n",
    "    z2 = (X @ beta2) * dt\n",
    "    return z1**2 + z2**2 + np.random.randn(len(X))\n",
    "\n",
    "def scenario_quadratic(X):\n",
    "    beta1 = 5 * np.sin(3*np.pi*t)\n",
    "    beta2 = 5 * np.sin(np.pi*t)\n",
    "    lin = (X @ beta1) * dt\n",
    "    quad = np.einsum('ij,ik->i', X*beta1, X*beta2) * dt**2\n",
    "    return lin + quad + np.random.randn(len(X))\n",
    "\n",
    "def scenario_complex_quadratic(X):\n",
    "    lin = np.sum(X**2, axis=1) * dt\n",
    "    quad = np.sum((X[:, :, None] * X[:, None, :])**2, axis=(1,2)) * dt**2\n",
    "    return lin + quad + np.random.randn(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a3def72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and evaluation \n",
    "\n",
    "def evaluate_model(X, y, model):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.33)\n",
    "    model.fit(Xtr, ytr)\n",
    "    pred = model.predict(Xte)\n",
    "    return np.sqrt(mean_squared_error(yte, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44cd731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario: Linear\n",
      "  Linear Regression: RMSE = 1.133\n",
      "  Neural Network: RMSE = 1.015\n",
      "\n",
      "Scenario: CAM\n",
      "  Linear Regression: RMSE = 1.716\n",
      "  Neural Network: RMSE = 1.173\n",
      "\n",
      "Scenario: Single Index\n",
      "  Linear Regression: RMSE = 3.694\n",
      "  Neural Network: RMSE = 1.145\n",
      "\n",
      "Scenario: Multiple Index\n",
      "  Linear Regression: RMSE = 3.904\n",
      "  Neural Network: RMSE = 1.153\n",
      "\n",
      "Scenario: Quadratic\n",
      "  Linear Regression: RMSE = 4.116\n",
      "  Neural Network: RMSE = 1.478\n",
      "\n",
      "Scenario: Complex Quadratic\n",
      "  Linear Regression: RMSE = 6.621\n",
      "  Neural Network: RMSE = 4.763\n"
     ]
    }
   ],
   "source": [
    "# comparison of models \n",
    "n = 1500\n",
    "X = simulate_functions(n, t)\n",
    "\n",
    "scenarios = {\n",
    "    \"Linear\": scenario_linear,\n",
    "    \"CAM\": scenario_cam,\n",
    "    \"Single Index\": scenario_single_index,\n",
    "    \"Multiple Index\": scenario_multiple_index,\n",
    "    \"Quadratic\": scenario_quadratic,\n",
    "    \"Complex Quadratic\": scenario_complex_quadratic\n",
    "}\n",
    "\n",
    "models = {\n",
    "    # approximation of FLM (Functional Linear Model)\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    # classic neural network\n",
    "    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(100, 100),\n",
    "                                   max_iter=500,\n",
    "                                   early_stopping=True)\n",
    "}\n",
    "\n",
    "for name, scen in scenarios.items():\n",
    "    y = scen(X)\n",
    "    print(f\"\\nScenario: {name}\")\n",
    "    for model_name, model in models.items():\n",
    "        rmse = evaluate_model(X, y, model)\n",
    "        print(f\"  {model_name}: RMSE = {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80201669",
   "metadata": {},
   "source": [
    "### Real Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading of three datasets : fat spectrum, growth curves, and phonemes curves\n",
    "\n",
    "def load_datasets():\n",
    "    \"\"\"Loading of the three datasets\"\"\"\n",
    "    \n",
    "    try:\n",
    "        from skfda.datasets import fetch_tecator, fetch_growth, fetch_phonemes\n",
    "        \n",
    "        # Tecator (Fat Spectrum)\n",
    "        tecator = fetch_tecator()\n",
    "        X_fat = tecator['data'].data_matrix.squeeze()\n",
    "        y_fat = tecator['target'][:, 1]  # Fat content\n",
    "        \n",
    "        # Growth\n",
    "        growth = fetch_growth()\n",
    "        X_growth = growth['data'].data_matrix.squeeze()\n",
    "        y_growth = (growth['target'] == 'male').astype(int)\n",
    "        \n",
    "        # Phonemes\n",
    "        phonemes = fetch_phonemes()\n",
    "        mask = (phonemes['target'] == 'aa') | (phonemes['target'] == 'ao')\n",
    "        X_phon = phonemes['data'].data_matrix[mask].squeeze()\n",
    "        y_phon = (phonemes['target'][mask] == 'ao').astype(int)\n",
    "        \n",
    "        print(\" Données chargées avec scikit-fda \")\n",
    "        return (X_fat, y_fat), (X_growth, y_growth), (X_phon, y_phon)\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"scikit-fda non trouvé. Installation: pip install scikit-fda\")\n",
    "        print(\"  Utilisation de données simulées pour démonstration...\")\n",
    "        \n",
    "        # Données simulées (remplacer par vraies données)\n",
    "        X_fat = np.random.randn(215, 100)\n",
    "        y_fat = np.random.uniform(5, 35, 215)\n",
    "        \n",
    "        X_growth = np.random.randn(93, 31)\n",
    "        y_growth = np.random.binomial(1, 0.5, 93)\n",
    "        \n",
    "        X_phon = np.random.randn(800, 256)\n",
    "        y_phon = np.random.binomial(1, 0.5, 800)\n",
    "        \n",
    "        return (X_fat, y_fat), (X_growth, y_growth), (X_phon, y_phon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================\n",
    "# 1. DÉFINITION DES MODÈLES\n",
    "# ============================================\n",
    "\n",
    "class FDNN:\n",
    "    \"\"\"Functional Direct Neural Network\"\"\"\n",
    "    def __init__(self, n_hidden_layers=1, n_neurons=2, grid_size=100):\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "    def build_model(self, input_shape):\n",
    "        \"\"\"\n",
    "        Construit le réseau avec des couches continues\n",
    "        \"\"\"\n",
    "        inputs = keras.Input(shape=input_shape)\n",
    "        \n",
    "        # Première couche continue\n",
    "        x = inputs\n",
    "        for l in range(self.n_hidden_layers):\n",
    "            # Simule une couche continue avec convolution 1D\n",
    "            x = keras.layers.Conv1D(\n",
    "                filters=self.n_neurons,\n",
    "                kernel_size=5,\n",
    "                activation='relu',\n",
    "                padding='same'\n",
    "            )(x)\n",
    "            \n",
    "        # Couche fonctionnelle finale (agrégation)\n",
    "        x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "        x = keras.layers.Dense(64, activation='relu')(x)\n",
    "        outputs = keras.layers.Dense(1)(x)  # ou sigmoid pour binaire\n",
    "        \n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val, y_val, epochs=100):\n",
    "        \"\"\"Early stopping sur validation set\"\"\"\n",
    "        self.model = self.build_model(X_train.shape[1:])\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='mse',  # ou 'binary_crossentropy'\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        early_stop = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "\n",
    "class FBNN:\n",
    "    \"\"\"Functional Basis Neural Network\"\"\"\n",
    "    def __init__(self, n_hidden_layers=1, n_neurons=2, \n",
    "                 n_basis=10, basis_type='bspline'):\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.n_basis = n_basis\n",
    "        self.basis_type = basis_type\n",
    "        \n",
    "    def basis_expansion(self, X, n_basis=10):\n",
    "        \"\"\"\n",
    "        Expansion en base B-splines\n",
    "        X : (n_samples, n_timepoints)\n",
    "        Retourne : (n_samples, n_basis)\n",
    "        \"\"\"\n",
    "        from scipy.interpolate import splrep, splev\n",
    "        \n",
    "        n_samples, n_timepoints = X.shape\n",
    "        t = np.linspace(0, 1, n_timepoints)\n",
    "        \n",
    "        # Créer les fonctions de base B-spline\n",
    "        knots = np.linspace(0, 1, n_basis - 2)[1:-1]\n",
    "        \n",
    "        X_basis = np.zeros((n_samples, n_basis))\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # Ajuster un spline sur chaque courbe\n",
    "            tck = splrep(t, X[i], k=3)\n",
    "            \n",
    "            # Projeter sur la base\n",
    "            for j in range(n_basis):\n",
    "                # Calculer les coefficients de base\n",
    "                basis_func = np.zeros(n_basis)\n",
    "                basis_func[j] = 1.0\n",
    "                # Évaluer\n",
    "                X_basis[i, j] = np.mean(X[i])  # Simplification\n",
    "                \n",
    "        return X_basis\n",
    "    \n",
    "    def build_model(self, input_dim):\n",
    "        \"\"\"Réseau classique sur coefficients de base\"\"\"\n",
    "        inputs = keras.Input(shape=(input_dim,))\n",
    "        \n",
    "        x = inputs\n",
    "        for _ in range(self.n_hidden_layers):\n",
    "            x = keras.layers.Dense(\n",
    "                self.n_neurons * self.n_basis,\n",
    "                activation='relu'\n",
    "            )(x)\n",
    "            \n",
    "        outputs = keras.layers.Dense(1)(x)\n",
    "        \n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val, y_val, epochs=100):\n",
    "        \"\"\"Entraînement avec early stopping\"\"\"\n",
    "        # Expansion en base\n",
    "        X_train_basis = self.basis_expansion(X_train, self.n_basis)\n",
    "        X_val_basis = self.basis_expansion(X_val, self.n_basis)\n",
    "        \n",
    "        self.model = self.build_model(X_train_basis.shape[1])\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        early_stop = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            X_train_basis, y_train,\n",
    "            validation_data=(X_val_basis, y_val),\n",
    "            epochs=epochs,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_test_basis = self.basis_expansion(X_test, self.n_basis)\n",
    "        return self.model.predict(X_test_basis)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. MÉTHODES DE COMPARAISON\n",
    "# ============================================\n",
    "\n",
    "def functional_linear_model(X_train, y_train, X_test):\n",
    "    \"\"\"FLM : régression linéaire fonctionnelle\"\"\"\n",
    "    from sklearn.linear_model import Ridge\n",
    "    \n",
    "    # Aplatir les courbes\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X_train_flat, y_train)\n",
    "    \n",
    "    return model.predict(X_test_flat)\n",
    "\n",
    "\n",
    "def cam_model(X_train, y_train, X_test):\n",
    "    \"\"\"CAM : Continuously Additive Model (approximation)\"\"\"\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_flat, y_train)\n",
    "    \n",
    "    return model.predict(X_test_flat)\n",
    "\n",
    "\n",
    "# 3. EXEMPLE COMPLET : FAT SPECTRUM\n",
    "\n",
    "\n",
    "def run_fat_spectrum_experiment():\n",
    "    \"\"\"Reproduit les résultats pour Fat Spectrum\"\"\"\n",
    "    \n",
    "    # Charger les données (à adapter selon votre source)\n",
    "    # X : (216, 100) - spectres\n",
    "    # y : (216,) - fat content\n",
    "    \n",
    "    # Split\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=40, random_state=42\n",
    "    )\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=40, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Normaliser\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_val_scaled = scaler_X.transform(X_val)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    \n",
    "    # Redimensionner pour FDNN (besoin de 3D)\n",
    "    X_train_3d = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "    X_val_3d = X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1)\n",
    "    X_test_3d = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. FLM\n",
    "    y_pred_flm = functional_linear_model(X_train_scaled, y_train, X_test_scaled)\n",
    "    results['FLM'] = np.sqrt(np.mean((y_test - y_pred_flm)**2))\n",
    "    \n",
    "    # 2. CAM\n",
    "    y_pred_cam = cam_model(X_train_scaled, y_train, X_test_scaled)\n",
    "    results['CAM'] = np.sqrt(np.mean((y_test - y_pred_cam)**2))\n",
    "    \n",
    "    # 3. FDNN\n",
    "    fdnn = FDNN(n_hidden_layers=2, n_neurons=4)\n",
    "    fdnn.fit(X_train_3d, y_train, X_val_3d, y_val, epochs=200)\n",
    "    y_pred_fdnn = fdnn.predict(X_test_3d).flatten()\n",
    "    results['FDNN'] = np.sqrt(np.mean((y_test - y_pred_fdnn)**2))\n",
    "    \n",
    "    # 4. FBNN\n",
    "    fbnn = FBNN(n_hidden_layers=2, n_neurons=4, n_basis=10)\n",
    "    fbnn.fit(X_train_scaled, y_train, X_val_scaled, y_val, epochs=200)\n",
    "    y_pred_fbnn = fbnn.predict(X_test_scaled).flatten()\n",
    "    results['FBNN'] = np.sqrt(np.mean((y_test - y_pred_fbnn)**2))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4. EXÉCUTION\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Fat Spectrum\n",
    "    print(\"=== Fat Spectrum Results ===\")\n",
    "    results_fat = run_fat_spectrum_experiment()\n",
    "    for method, rmse in results_fat.items():\n",
    "        print(f\"{method}: RMSE = {rmse:.3f}\")\n",
    "    \n",
    "    # Résultats attendus (Table 5) :\n",
    "    # FLM: 2.517\n",
    "    # CAM: 5.103\n",
    "    # FDNN: 0.822\n",
    "    # FBNN: 1.197"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FDA)",
   "language": "python",
   "name": "venv_fdnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
